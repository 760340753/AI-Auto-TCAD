# ==================================================================
# SYNOPSYS CONFIDENTIAL - This is an unpublished, proprietary work
# of Synopsys, Inc., and is fully protected under copyright and
# trade secret laws. You may not view, use, disclose, copy, or
# distribute this file or any information contained herein except
# pursuant to a valid written license from Synopsys.
# ==================================================================


"""SWB API adapter for Python Job scheduling engines."""


from __future__ import annotations


import os as _os

from ast import literal_eval as _literal_eval
from contextlib import contextmanager as _contextmanager
from enum import Enum as _Enum
from functools import partial as _partial

from logging import (  # noqa: N813
    getLogger as _get_logger,
    basicConfig as _configure_root_logger,
)

from os import (
    PathLike as _PathLike,
    environ as _environ,
)

from shutil import which as _which

from subprocess import (  # noqa: S404
    PIPE as _PIPE,
    run as _run,
)

from sys import executable as _current_python_interpreter

from typing import (
    cast as _cast,
    MutableMapping as _MutableMapping,
    NamedTuple as _NamedTuple,
    NewType as _NewType,
    Optional as _Optional,
    TYPE_CHECKING as _TYPE_CHECKING,
)

from warnings import warn as _warn


from pyparsing import (  # noqa: N813
    Combine as _Combine,
    Keyword as _Keyword,
    Literal as _Literal,
    NotAny as _NotAny,
    oneOf as _one_of,
    Or as _Or,
    ParserElement as _ParserElement,
    printables as _printables,
    QuotedString as _QuotedString,
    Regex as _Regex,
    Word as _Word,
    ZeroOrMore as _ZeroOrMore,
)

from swbutils.common.Utils import configure_logging
configure_logging()

from rayuela import (
    get_infrastructure as _get_infrastructure,
    submit_command as _submit_command,
)

from rayuela.task import (
    Status as _RayuelaStatus,
    Task as _Task,
)

from rayuela.infrastructures.infrastructure import Infrastructure as _Infrastructure


try:
    from guanaco import CDPLInfraSpec as _CDPLInfraSpec

    CDPL_AVAILABLE = True

except Exception:
    CDPL_AVAILABLE = False


if _TYPE_CHECKING:
    from _typeshed import StrOrBytesPath as _StrOrBytesPath


if "SWB_SCHEDULING_LOG_FILE" in _environ:
    _configure_root_logger(
        filename=_environ["SWB_SCHEDULING_LOG_FILE"],
        level="DEBUG",
        format="%(asctime)s %(levelname)-8s [%(pathname)s:%(lineno)d] %(message)s",
        datefmt="%Y-%m-%d:%H:%M:%S",
    )

    _get_logger(__name__).warning(
        "Scheduling log file was enabled using the environment variable "
        "SWB_SCHEDULING_LOG_FILE. This will break logging at the application level! "
        "Please only use this for debugging purposes."
    )


def _env_extraction_arguments(executable, setup_script, extra_env=None):
    return {
        "args": (
            f"source {setup_script} "
            f"&& python -c 'from os import environ; print(repr({{**environ}}))'"
        ),
        "executable": executable,
        "shell": True,
        "stdout": _PIPE,
        "env": {**_os.environ, **(extra_env or {})},
    }


known_cells = {
    "lsf_tcad": _env_extraction_arguments(
        "csh", "/remote/lsf/cells/tcad/conf/cshrc.lsf"
    ),
    "rtda_snps": _env_extraction_arguments(
        "csh", "/remote/cfadm/rtda/snps/common/etc/vovrc.csh", {"NC_QUEUE": "vnc"}
    ),
    "sge_snps": _env_extraction_arguments(
        "bash", "/remote/sge/cells/snps/common/settings.sh"
    ),
    "sge_tcad": _env_extraction_arguments(
        "bash", "/remote/sge/cells/tcad/common/settings.sh"
    ),
    "slurm_snps_gpu": _env_extraction_arguments(
        "bash", "/remote/cfadm/slurm/cells/snps-gpu/slurm.sh"
    ),
    "slurm_snps": _env_extraction_arguments(
        "bash", "/remote/cfadm/slurm/snps/slurm.sh"
    ),
}


@_contextmanager
def _cell_environment(env_extraction_arguments):
    old_environ = _os.environ.copy()

    try:
        env = _run(**env_extraction_arguments).stdout.decode()  # noqa: S603
        env = _literal_eval(env)
        _os.environ.update(env)

        yield

    finally:
        _os.environ.clear()
        _os.environ.update(old_environ)


def _store_results(parser, name):
    return parser.setResultsName(name, listAllMatches=True)


def _store_transformed(parser, name, function):
    return _store_results(parser, name).setParseAction(
        lambda s, loc, toks: function(toks)
    )


def _store_concatenated(parser, name, char=" "):
    return _store_transformed(parser, name, lambda toks: " ".join(toks))


def _store_ints(parser, name):
    return _store_transformed(parser, name, lambda toks: int(toks[0]))


def _copy_option(
    source_dict, target_dict, source_key, target_key, transformation=lambda v: v
):
    if source_key in source_dict:
        target_dict[target_key] = transformation(source_dict[source_key])

    else:
        pass


_copy_last = _partial(_copy_option, transformation=lambda l: l[-1])


def _ignore(parser: _ParserElement):
    def show_warning(s, loc, toks):  # noqa: VNE001
        _warn(f"Ignoring requirement {' '.join(toks)}.", RuntimeWarning)

    return parser.setParseAction(show_warning).suppress()


def _param_value(unquote=True):
    return _QuotedString('"', unquoteResults=unquote) | _Word(
        _printables.replace("-", ""), _printables
    )


_single_dash_keyword = _Combine(_NotAny("--") + "-" + _Regex(r"\S")[1, ...])
_double_dash_keyword = _Combine("--" + _Regex(r"\S")[1, ...])
_yes_or_no = _one_of("y yes n no")

_sge_style_params = _store_concatenated(
    _single_dash_keyword + _param_value(unquote=False)[0, ...],
    "others",
)

_slurm_style_params = _store_concatenated(
    _Combine(
        _double_dash_keyword + _Literal("=")[0, 1] + _param_value(unquote=False)[0, ...]
    ),
    "others",
)

_other_params = _slurm_style_params | _sge_style_params


class InvalidEngineError(ValueError):
    """Raise if a specified engine is not recognized.

    >>> raise InvalidEngineError("non_existent_engine")
    Traceback (most recent call last):
    swbutils.scheduler.InvalidEngineError: non_existent_engine is not recognized as ...
    """

    def __init__(self, engine):
        """Set an appropriate message based on the specified engine."""
        super().__init__(f"{engine} is not recognized as a valid engine")


class Engine(_Enum):
    """Supported engines."""

    CDPL = "cdpl"
    RAYUELA = "rayuela"


class Scheduler(_Enum):
    """Supported schedulers.

    .. todo::
        *   Enable more schedulers like: MOAB.
    """

    LOCAL = "local"
    LSF = "lsf"
    PBS = "pbs"
    RTDA = "rtda"
    SGE = "sge"
    SLURM = "slurm"


class TaskIsNotAliveError(RuntimeError):
    """Rise when operation cannot finish due to task not on any worker.

    Some operations may not be able to complete because a task is not
    assigned to any worker. In these cases there is no matching job for
    that task and also no worker to talk to.

    This is normal and happens usually when the task is pending.

    .. note::
        This error simply expresses a high probability that this is
        true. We do not directly check that this is true before rising
        this exception, we are just reacting to the symptoms.
    """

    def __init__(self, key):
        """Initialize the exception with a predefined message."""
        super().__init__(f"Task {key} is not assigned to any worker.")


SchedulerID = _NewType("SchedulerID", int)


class SchedulerSpec(_NamedTuple):
    """Specification of a scheduler.

    This tuple contains all the information needed to send a task to a
    specific scheduler.
    """

    scheduler: Scheduler
    engine: Engine
    cell: str | None
    cell_initscript: _StrOrBytesPath | None


TaskKey = _NewType("TaskKey", str)
TaskStatus = _NewType("TaskStatus", str)


class TaskEntry:
    """A task entry in an :class:`SWBRunEngine`.

    This class is used to maintain a reference to a :mod:`rayuela` task.
    It is very important to keep a reference to the task in order to
    avoid the task being garbage collected and thus losing track of it.

    This is needed because the program that consumes this API only keeps
    an opaque reference to the task, i.e. a string. This is not enough
    to keep the task alive. We need to keep a registry of all the tasks
    that are alive and keep a reference to them.

    If the task completes successfully, the task reference is removed
    and the task is garbage collected.

    When we detect that a task is not alive anymore, we can still
    retrieve the last status of the task from the scheduler. This is
    useful to know if the task was successful or not.
    """

    def __init__(
        self,
        run_engine: "SWBRunEngine",
        scheduler_id: SchedulerID,
        task: _Optional[_Task] = None,
        status: _Optional[TaskStatus] = None,
    ):
        """Initialize the task entry.

        :param run_engine: The run engine that created this task entry.
        :param scheduler_id: The scheduler id of the task.
        :param task: The task object.
        :param status: The last known status of the task.

        :raises RuntimeError:
            If both task and status are provided or if none of them are
            provided.
        """
        if task is not None and status is not None:
            raise RuntimeError(
                f"{self.__class__.__name__} cannot be created with both task and "
                f"status arguments. Please choose one of the arguments."
            )

        if task is None and status is None:
            raise RuntimeError(
                f"{self.__class__.__name__} cannot be created without a task and "
                f"status arguments. Please provide one of the arguments."
            )

        self._run_engine = run_engine
        self.scheduler_id = scheduler_id
        self.task = task
        self._last_status = status

    @property
    def status(self) -> TaskStatus:
        """Get the status of the task.

        If the task is not alive anymore, the last known status of the
        task is returned. If the task is alive, the status is retrieved
        from the task.

        If the task is completed, the task reference is removed and the
        task is garbage collected.
        """
        if self.has_engine_references:  # noqa: R505
            status = self._get_status_from_task()

            if status == "completed":
                self.free()

            return status

        else:
            assert self._last_status is not None
            return self._last_status

    @status.setter
    def status(self, new_status):
        self.task = None
        self._last_status = new_status

    def free(self):
        """Free the task entry.

        Assigning to ``self.status`` will remove the reference to
        ``self.task`` and set ``self._last_status`` to the current
        status of the task.
        """
        if self.has_engine_references:
            self.status = self._get_status_from_task()

        else:
            pass

    def _get_status_from_task(self):
        return {
            _RayuelaStatus.CANCELLED: "completed",
            _RayuelaStatus.ERROR: "completed",
            _RayuelaStatus.FINISHED: "completed",
            _RayuelaStatus.LOST: "unknown",
            _RayuelaStatus.PENDING: "pending",
            _RayuelaStatus.RUNNING: "running",
        }[self.task.status]

    @property
    def has_engine_references(self):
        """Return True if ``self.task`` is not None.

        Keeping a reference to an engine task may prevent resources from
        being freed.
        """
        return self.task is not None

    def stop(self):
        """Stop the task."""
        if not self.has_engine_references:
            return

        self.task.cancel()
        self.free()


class SWBRunEngine:
    r"""Run SWB jobs using different engines.

    >>> from time import sleep
    >>> from warnings import catch_warnings, filterwarnings
    >>> from pathlib import Path

    >>> run_engine = SWBRunEngine()
    >>> scheduler = run_engine.add_scheduler("sge")
    >>> stdout = Path.cwd() / "test.txt"

    >>> with catch_warnings(record=True) as w:
    ...     filterwarnings("always", r"Ignoring requirement.*")
    ...
    ...     job_id = run_engine.submit_job(
    ...         scheduler,
    ...         command='echo "Hello World!"',
    ...         outputFile=stdout,
    ...         reqs="-N test -P bnormal -j no",
    ...     )
    ...
    ...     print(w[-1].message)
    Ignoring requirement -j no.

    >>> while True:
    ...     sleep(1)
    ...     if run_engine.poll_job(job_id) == "completed":
    ...         break

    >>> with stdout.open() as f:
    ...     print(*f, sep="\n")
    Hello World!...

    >>> stdout.unlink()
    """

    def __init__(self) -> None:
        """Initialize internal scheduler and task containers."""
        self.schedulers: _MutableMapping[SchedulerID, SchedulerSpec] = {}
        self._tasks: _MutableMapping[TaskKey, TaskEntry] = {}

    def add_scheduler(
        self,
        scheduler: Scheduler | str,
        engine: Engine | str = Engine.RAYUELA,
        cell: str | None = None,
        cell_initscript: _StrOrBytesPath | None = None,
    ) -> SchedulerID:
        """Create a new scheduler entry in the internal dictionary.

        :param engine: "rayuela" | "cdpl"

        :param scheduler:
            "local" | "sge" | "lsf" | "slurm" | ...

        :param cell:
            Name of a known cell. For example, in US01 we have multiple
            UGE cells for TCAD: 'tcad', 'snps', 'proteus_dev', etc.

        :param cell_initscript:
            If cell is not defined, we launch this command to initialize
            settings of the scheduler, e.g. ``source
            /remote/sge/cells/tcad/common/settings.csh``. In general, we
            can require that customer encapsulates scheduler init
            setting in a script.

        :return:
            An internal scheduler ID, should be unique in the scope of
            SWBRunEngine.

        Passing a non supported scheduler string should fail with an
        appropriate message::

            >>> run_engine = SWBRunEngine()
            >>> scheduler = run_engine.add_scheduler("unknown")
            Traceback (most recent call last):
            ValueError: 'unknown' is not a valid Scheduler

        If neither cell nor cell_initscript are defined, it is assumed
        that the scheduler is already initialized and ready to use.
        """
        scheduler_spec = SchedulerSpec(
            Scheduler(scheduler), Engine(engine), cell, cell_initscript
        )

        scheduler_id = _cast(SchedulerID, hash(scheduler_spec))

        self.schedulers[scheduler_id] = scheduler_spec
        return scheduler_id

    def submit_job(
        self,
        schedulerID: SchedulerID,  # noqa: N803
        command,
        outputFile=None,
        errorFile=None,
        reqs="",
        custom_python_shell=None,
        log_directory=None,
    ) -> TaskKey:
        """Submit a command job on a specific scheduler.

        :param schedulerID:
            Where to send the job, this is the ID returned by
            add_scheduler().

        :param command:
            what to launch, e.g. "gjob -verbose -job 31
            /path/to/my/project".

        :param outputFile:
            stdout of the "command".

        :param errorFile:
            stderr of the "command".

        :param reqs:
            String with additional options for the job scheduler command.

        :return:
            An internal ID of the job, should be unique in the scope of
            :class:`SWBRunEngine`.

        :raises InvalidEngineError:
            If the engine is not supported.

        1.  Runs cell_initscript command (if any).
        2.  Starts a worker.
        3.  Waits until a worker has been submitted, or raises an error if submission
            failed.
        """
        engine = self.schedulers[schedulerID].engine

        if engine is Engine.RAYUELA:  # noqa: R505
            return self._submit_command_using_rayuela(
                schedulerID,
                command,
                outputFile,
                errorFile,
                reqs,
                custom_python_shell,
                log_directory,
            )

        elif engine is Engine.CDPL and CDPL_AVAILABLE:
            return self._submit_command_using_cdpl(
                schedulerID,
                command,
                outputFile,
                errorFile,
                reqs,
                custom_python_shell,
                log_directory,
            )

        else:
            raise InvalidEngineError(engine)

    def _get_valid_interpreter(
        self, python_interpreter: _PathLike[str] | str | None = None
    ) -> str:
        return str(
            python_interpreter
            or _which("gpythonsh")
            or _which("python3")
            or _which("python")
            or _current_python_interpreter
        )

    def _submit_command_using_cdpl(
        self,
        schedulerID: SchedulerID,  # noqa: N803
        command,
        outputFile,
        errorFile,
        reqs,
        remote_python_interpreter=None,
        log_directory=None,
    ) -> TaskKey:
        """Submit a command on a specific scheduler.

        :param schedulerID:
            Where to send the job, this is the ID returned by
            :meth:`add_scheduler`.

        :param command:
            What to launch, e.g. ``gjob -verbose -job 31
            /path/to/my/project``.

        :param outputFile:
            stdout of the ``command``.

        :param errorFile:
            stderr of the ``command``.

        :param reqs:
            String with additional options for the job scheduler
            command.

        :return: An internal ID of the job.

        .. todo::

            :class:`~guanaco.CDPLInfraSpec` has arguments: ``infra``,
            ``hostname``, ``slots``, ``tmpdir``, ``extra_cmd_options``
            and ``command``. From those, we can only set ``infra`` and
            ``extra_cmd_options``. We should be able to set the rest of
            the arguments, but there is no way to do it right now.
        """
        scheduler = self.schedulers[schedulerID].scheduler

        kwargs = {
            "infra_name": "cdpl",
            "infra_args": {
                "cdpl_infra_spec": _CDPLInfraSpec(
                    scheduler.value,
                    extra_cmd_options=reqs,
                    command=(
                        "nc run"
                        if scheduler is Scheduler.RTDA
                        else None
                        # This is a workaround for a bug in Guanaco
                    ),
                ),
                "remote_python_interpreter": self._get_valid_interpreter(
                    remote_python_interpreter
                ),
            },
        }

        task = _submit_command(command, stdout=outputFile, stderr=errorFile, **kwargs)
        self._tasks[task.key] = TaskEntry(self, schedulerID, task)
        return task.key

    def _make_default_dask_jobqueue_based_kwargs(
        self, infra_name, remote_python_interpreter=None
    ):
        return {
            "infra_name": infra_name,
            "infra_args": {
                "python": self._get_valid_interpreter(remote_python_interpreter)
            },
        }

    def _parse_rayuela_sge_params(
        self, requirements, remote_python_interpreter=None, log_directory=None
    ):
        name_param = _Keyword("-N") + _store_results(_param_value(), "names")
        notify_param = _Keyword("-notify")
        now_param = _Keyword("-now") + _yes_or_no
        project_param = _Keyword("-P") + _store_results(_param_value(), "projects")
        queue_param = _Keyword("-q") + _store_results(_param_value(), "queues")

        resource_spec_param = _Keyword("-l") + _store_results(
            _param_value(), "resource_specs"
        )

        stderr_merge_param = _Keyword("-j") + _yes_or_no

        sge_requirements = _ZeroOrMore(  # noqa: ECE001
            _ignore(notify_param)
            | _ignore(now_param)
            | _ignore(stderr_merge_param)
            | name_param
            | project_param
            | queue_param
            | resource_spec_param
            | _other_params  # should always be final!
        )

        parsed_options = sge_requirements.parseString(requirements)

        kwargs = self._make_default_dask_jobqueue_based_kwargs(
            "sge", remote_python_interpreter
        )

        infra_args = kwargs["infra_args"]

        if parsed_options:
            copy = _partial(_copy_option, parsed_options, infra_args)
            copy_last = _partial(_copy_last, parsed_options, infra_args)

            copy_last("names", "name")
            copy_last("projects", "project")
            copy_last("queues", "queue")
            copy("others", "job_extra_directives", list)
            copy("resource_specs", "resource_spec", ",".join)

        if log_directory is not None:
            infra_args["log_directory"] = log_directory

        return kwargs

    def _parse_rayuela_lsf_params(
        self, requirements, remote_python_interpreter=None, log_directory=None
    ):
        # Note:
        #   this modification broke the tests. I do not know why this was needed.
        #   See https://jira.internal.synopsys.com/browse/P10003710-23964.
        #
        # mem_param = _Keyword("-M") + _Combine(  # noqa: E800
        #     _store_ints(_param_value(), "mems")  # noqa: E800
        #     + _store_results(_Word(_alphas), "lsf_units")  # noqa: E800
        # )  # noqa: E800

        mem_param = _Keyword("-M") + _store_ints(_param_value(), "mems")
        name_param = _Keyword("-J") + _store_results(_param_value(), "names")
        ncpus_param = _Keyword("-n") + _store_ints(_param_value(), "ncpu_values")
        project_param = _Keyword("-P") + _store_results(_param_value(), "projects")
        queue_param = _Keyword("-q") + _store_results(_param_value(), "queues")

        lsf_requirements = _ZeroOrMore(
            mem_param
            | name_param
            | ncpus_param
            | project_param
            | queue_param
            | _other_params
        )

        parsed_options = lsf_requirements.parseString(requirements)

        kwargs = self._make_default_dask_jobqueue_based_kwargs(
            "lsf", remote_python_interpreter
        )

        infra_args = kwargs["infra_args"]

        if parsed_options:
            copy = _partial(_copy_option, parsed_options, infra_args)
            copy_last = _partial(_copy_last, parsed_options, infra_args)
            copy_last("names", "name")
            copy_last("projects", "project")
            copy_last("queues", "queue")
            copy("mems", "mem", lambda l: l[0])
            copy("ncpu_values", "ncpus", lambda l: l[0])
            copy("others", "job_extra_directives", list)

            if log_directory is not None:
                infra_args["log_directory"] = log_directory

        if log_directory is not None:
            infra_args["log_directory"] = log_directory

        return kwargs

    def _parse_rayuela_local_params(
        self, requirements, remote_python_interpreter=None, log_directory=None
    ):
        if remote_python_interpreter is not None:
            _warn(
                "Ignoring custom_python_shell argument. The local infrastructure does "
                "not support choosing a custom python shell.",
                RuntimeWarning,
            )

        return {"infra_name": "local"}

    def _parse_rayuela_slurm_params(
        self, requirements, remote_python_interpreter=None, log_directory=None
    ):
        mem_param = _Combine(
            _Keyword("--mem") + "=" + _store_results(_param_value(), "mems")
        )

        name_param = _Combine(
            _Or([_Keyword("-J"), _Keyword("--job-name")])
            + "="
            + _store_results(_param_value(), "names")
        )

        ncpus_param = _Combine(
            _Or([_Keyword("-c"), _Keyword("--cpus-per-task")])
            + "="
            + _store_ints(_param_value(), "ncpu_values")
        )

        project_param = _Combine(
            _Or([_Keyword("-A"), _Keyword("--account")])
            + "="
            + _store_results(_param_value(), "projects")
        )

        queue_param = _Combine(
            _Or([_Keyword("-p"), _Keyword("--partition")])
            + "="
            + _store_results(_param_value(), "queues")
        )

        slurm_requirements = _ZeroOrMore(
            mem_param
            | name_param
            | ncpus_param
            | project_param
            | queue_param
            | _other_params
        )

        parsed_options = slurm_requirements.parseString(requirements)

        kwargs = self._make_default_dask_jobqueue_based_kwargs(
            "slurm", remote_python_interpreter
        )

        infra_args = kwargs["infra_args"]

        if parsed_options:
            copy = _partial(_copy_option, parsed_options, infra_args)
            copy_last = _partial(_copy_last, parsed_options, infra_args)
            copy_first = _partial(copy, transformation=lambda l: l[0])

            copy_last("names", "job_name")
            copy_last("projects", "project")
            copy_last("queues", "queue")
            copy_first("mems", "job_mem")
            copy_first("ncpu_values", "job_cpu")
            copy("others", "job_extra_directives", list)

        if log_directory is not None:
            infra_args["log_directory"] = log_directory

        return kwargs

    def _parse_rayuela_parameters(
        self,
        scheduler,
        requirements: str,
        remote_python_interpreter=None,
        log_directory=None,
    ):
        if scheduler is Scheduler.SGE:  # noqa: R505
            return self._parse_rayuela_sge_params(
                requirements, remote_python_interpreter, log_directory
            )

        elif scheduler is Scheduler.LSF:
            return self._parse_rayuela_lsf_params(
                requirements, remote_python_interpreter, log_directory
            )

        elif scheduler is Scheduler.LOCAL:
            return self._parse_rayuela_local_params(
                requirements, remote_python_interpreter, log_directory
            )

        elif scheduler is Scheduler.SLURM:
            return self._parse_rayuela_slurm_params(
                requirements, remote_python_interpreter, log_directory
            )

        else:
            raise RuntimeError(f"Cannot submit command using {scheduler}")

    def _job_script(self, infra_name, infra_args=None, **kwargs) -> str:
        """Return the job script to be submitted to the scheduler.

        :param infra_name: The name of the infrastructure to use.
        :param infra_args: The arguments to pass to the infrastructure.
        :param kwargs: Ignored.
        :return: The job script.
        """
        infra_args = infra_args or {}

        infrastructure: _Infrastructure = _get_infrastructure(
            infra_name=infra_name, infra_args=infra_args
        )

        return f"Job script:\n{infrastructure.job_script}"

    def _show_job_script(self, infra_name, infra_args={}, **kwargs):  # noqa: B006
        try:
            print(self._job_script(infra_name, infra_args, **kwargs))

        except RuntimeError:
            print("No job script.")

    def _submit_command_using_rayuela(
        self,
        schedulerID,  # noqa: N803
        command,
        outputFile,
        errorFile,
        reqs,
        remote_python_interpreter=None,
        log_directory=None,
    ):
        scheduler = self.schedulers[schedulerID].scheduler

        kwargs = self._parse_rayuela_parameters(
            scheduler, reqs, remote_python_interpreter, log_directory
        )

        task = _submit_command(command, stdout=outputFile, stderr=errorFile, **kwargs)
        self._tasks[task.key] = TaskEntry(self, schedulerID, task)
        return task.key

    def free_job(self, task_key: TaskKey):
        """Free all job resources.

        Free all job resources, removing the actual task from the task
        entry and storing the last observed status instead.
        """
        self._tasks[task_key].free()

    def has_engine_references(self, task_key: TaskKey):
        """Return True when TaskEntry has refs to engine objects.

        :class:`TaskEntry` objects may keep references to engine objects
        and this in turn may prevent resources from being freed.

        This method let's you know if such references are being held.
        """
        return self._tasks[task_key].has_engine_references

    def poll_job(self, jobID):  # noqa: N803
        """Return the status of a job.

        :param jobID: An internal ID of a previously submitted job.

        :return:
            An internal status of the job. Supported statuses are:
            wrong, pending, running, suspended, completed, unknown.

        1.  Runs cell_initscript command (if any).
        2.  Requests on the status of the job.
        """
        return self._tasks[jobID].status

    def stop_job(self, jobID):  # noqa: N803
        """Stop a job.

        :param jobID:
            An internal ID of the job previously submitted, otherwise
            raise an error.

        1.  Runs cell_initscript command (if any)
        2.  Stops the job
        3.  Doesn't wait until the job has been stopped, returns
            immediately.
        """
        self._tasks[jobID].stop()

    def _get_task_attribute(self, key, attribute):
        task = self._tasks[key].task
        return getattr(task, attribute)

    def _get_one_of_task_iterable_attribute(self, key, attribute):
        """Return one of the elements of a task's iterable attributes.

        :raises TaskIsNotAliveError: If the task is not alive.
        :raises RuntimeError: If the task is alive but the attribute is not iterable.
        """
        try:
            iterable = self._get_task_attribute(key, attribute)
            iterator = iter(iterable)
            return next(iterator)

        except StopIteration as si:
            try:
                next(iterator)

            except StopIteration:
                raise TaskIsNotAliveError(key) from si

            else:
                raise

        except TypeError as te:
            try:
                iter(iterable)

            except TypeError:
                raise RuntimeError(f"{attribute} is not iterable") from te

            else:
                raise

    def get_native_job_id(self, jobID) -> str:  # noqa: N803
        """Return one of the native job ids running this task."""
        try:
            return self._get_one_of_task_iterable_attribute(jobID, "native_job_ids")

        except Exception:
            return "--"

    def get_host(self, jobID) -> str:  # noqa: N803
        """Return one of the hosts running this task."""
        return self._get_one_of_task_iterable_attribute(jobID, "host_names")
