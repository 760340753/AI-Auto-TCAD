# ==================================================================
# SYNOPSYS CONFIDENTIAL - This is an unpublished, proprietary work  
# of Synopsys, Inc., and is fully protected under copyright and     
# trade secret laws. You may not view, use, disclose, copy, or      
# distribute this file or any information contained herein except   
# pursuant to a valid written license from Synopsys.                
# ==================================================================

from swbutils.mongo.mongodb import MongoDB
from swbutils.mongo.mongologger import MongoLogger
from swbutils.mongo.mongoutil import MongoUtil
import ast
import json
from queue import Empty

class MongoSwbOperations:
    
    def __init__(self, connection):
        self.connection = connection
        self.lg = MongoLogger()
        #Todo: move to mongodb 
        self.DB_NAME = "SynopsysSWB"

    def IsSharedDB(self):
        dbs = self.connection.client.list_database_names()
        # more than 4 system DBs + swb + other
        if self.DB_NAME in dbs and len(dbs) > 5:
            return True
        return False

    def IsOtherDB(self):
        dbs = self.connection.client.list_database_names()
        # can only use this in connection with Marker File
        # in case of SWB DB being empty of collections due to import error
        # and we could not drop the DB.
        if self.DB_NAME in dbs:
            dbs.remove(self.DB_NAME)
        # more than 4 system DBs + other
        if len(dbs) > 4:
            return True
        return False
    

    def DropTheDB(self):
        try:
            self.connection.RemoveDB(self.DB_NAME)
            return True
        except Exception as ex:
            self.lg.Print(f"Failed to drop DB: {ex}")
            return ex

    def UpdateMetaData(self, col, qfunc, ddlist, many=True, upsertVal = True):
        #data sould be a list of dictionaries
        updated = 0
        inserted = 0
        if not hasattr(self.connection, 'Update'):
            return
        if isinstance(ddlist, list):
            for dd in ddlist:
                pydd = ast.literal_eval(dd)
                query = qfunc(pydd=pydd)
                resp = self.connection.Update(self.DB_NAME, col, query, pydd, many, upsert = upsertVal )
                if resp and resp.acknowledged :
                    if resp.raw_result['updatedExisting']:
                        updated += resp.modified_count
                    else:
                        updated += resp.modified_count
                        inserted += 1
                        self.lg.Print ("New data object, created ID = " + str(resp.upserted_id) )
            if updated > 0 or inserted > 0:
                if MongoUtil.IsMetaDbDebugEnabled():
                     self.lg.Print(f"UpdateMetaData: Documents updated {updated}, inserted {inserted}")        
        else:
            if MongoUtil.IsMetaDbDebugEnabled():
                raise Exception("UpdateMetaData: value is not a list")
        
    def RemoveFieldsFromProjectMetaData(self, fieldsToBeRemovedJson ):
        fieldsToBeRemovedBson = ast.literal_eval(fieldsToBeRemovedJson)
        emptyQuery = ast.literal_eval("{}")
        resp = self.connection.Update(self.DB_NAME, "Project", emptyQuery, fieldsToBeRemovedBson, False, True)

    def ResetNodeActiveStatuses(self):
        many = True
        raw = True
        upsert = False
        self.connection.Update(self.DB_NAME, "NodeRuntime", {"status":{"$in":["running","ready","pending","queued"]}}, {"$set": {"status":"none"}}, many, raw, upsert)

        
    def UpdateProjectMetaData(self, dictValues):
        many = False
        raw = True
        upsert = True
        
        updateDict = {}
        updateDict["$set"] =  json.loads(dictValues)
        self.connection.Update(self.DB_NAME, "Project", {}, updateDict, many, raw,  upsert)
                
    def ChangeNodeNumber(self, oldNumber, newNumber):
        self.connection.FindAndReplace(self.DB_NAME, "NodeVar", "node", oldNumber, newNumber)                
                    
    def UpdateNodeStatusMetaData(self, node, dd, upsert = False):
        # query function
        def _query(**kwargs):
            return {"node" : str(node)}
        
        ddlist = list()
        ddlist.append(dd)
        self.UpdateMetaData("NodeRuntime", _query  , ddlist, upsert) 

    # Fetch the doc from the NodeRuntime collection, update the _id and node fields and save in the NodeRuntimeTemp collection
    def AddUpdatedNodeToNodeRuntimeTemp(self, oldNode, newNode):
        oldNodeData = self.CollectNodeStatusMetaData(oldNode)
        if len(oldNodeData) > 0:
            oldNodeData["node"] = newNode
            oldNodeData["_id"] = newNode
            self.connection.Create(self.DB_NAME, "NodeRuntimeTemp", oldNodeData)



    def UpdateCollectionWithTempValue(self, collection, oldVal, newVal):
        many = True
        raw = True
        upsert = False
        self.connection.Update(self.DB_NAME, collection, {"node": oldVal }, {"$set": {"_Temp": newVal }}, many, raw, upsert)

    def RenameField(self, collection, oldField, newField):
        many = True
        raw = True        
        self.connection.Update(self.DB_NAME, collection, { }, {"$rename": {oldField : newField }}, many, raw)
        
    def UpdateNodeVariableMetaData(self, node, name, type, value, dd):
        varDict = { }


        varDict.update(ast.literal_eval(dd))
        varDict['value'] = value
        many = False
        resp = self.connection.Update(self.DB_NAME, "NodeVar", { "name" : name, "node" : node, "type" : type }, varDict, many)
        
    def UpdateToolMetaData(self, node, dd):
        # query function
        def _query(**kwargs):
            return {"tool" : str(node)}
        
        ddlist = list()
        ddlist.append(dd)

        self.UpdateMetaData("NodeRuntime", _query  , ddlist, False)         
        
    def SwapCollections(self, collection, temp_collection):
        self.connection.Remove(self.DB_NAME, collection)
        self.connection.Rename(self.DB_NAME, temp_collection, collection)
        self.connection.Remove(self.DB_NAME, temp_collection)

    def CleanupTempRenumberLocations(self):
        self.DeleteData("NodeRuntimeTemp")

    def RenumberNodesToTempLocations(self, oldNode, newNode):
        self.UpdateCollectionWithTempValue("NodeVar", oldNode, newNode)
        self.AddUpdatedNodeToNodeRuntimeTemp(oldNode, newNode)

    def SwapTempRenumberLocationsWithCurrentLocations(self):
        self.SwapCollections("NodeRuntime", "NodeRuntimeTemp")
        self.RenameField("NodeVar", "_Temp", "node" )

                
    def WriteDDString(self, dd, colname):
        count = 0
        #convert string rep of dict to actual dict
        pydd = ast.literal_eval(dd)
        resp = self.connection.Create(self.DB_NAME, colname, pydd)
        if resp.acknowledged :
            count = 1
                    
        return count                   
                
    def WriteListOfDDStrings(self, ddList, colname):
        #data should be a list of string rep dictionaries
        pylist = ddList.split("@@")
        count = 0
        if isinstance(pylist, list) :
            for dd in pylist:
                count += self.WriteDDString(dd, colname)
        if count > 0:
            self.lg.Print(f"Documents inserted {count}")        
        return True   
        
    def WriteMetaData(self, tname, ddList):
        #print(f"WriteMetaData - {tname} {ddList}")
        try:
            if not ddList:
                return True 
            if tname == 'gvars':
                return self.WriteListOfDDStrings( ddList, 'NodeVar')
            elif tname == 'gexec': 
                return self.WriteListOfDDStrings( ddList, 'ExecNode')
            elif tname == 'graph':
                result = self.WriteGraphData( ddList)
                return result
            else:
                self.lg.Print("Unknown data collection in write data")
                return False
        except Exception as ex:
            self.lg.Print ("Exception Saving: ", tname, ddList, "error:", ex )
            return False
        
        return True    
    
    def CollectGraphMetaData(self):
        MetaData = {}
        MetaData["Tools"] = self.connection.Read(self.DB_NAME, "Tool")
        MetaData["Parameters"] = self.connection.Read(self.DB_NAME, "Parameter")
        MetaData["Variables"] = self.connection.Read(self.DB_NAME, "Variable")
        MetaData["Scenarios"] = self.connection.Read(self.DB_NAME, "Scenario")
        MetaData["Nodes"] = self.connection.Read(self.DB_NAME, "Node")
        return MetaData
    
    def CollectProjectMetaData(self):
        metadata = self.connection.Read(self.DB_NAME, "Project") 
        jsonData=list() 
        if metadata:
            jsonData = metadata[0]
        return jsonData     
    
    def CollectGVarsMetaData(self):
        return self.connection.Read(self.DB_NAME, "NodeVar")
    
    def CollectGExecMetaData(self):
        return self.connection.Read(self.DB_NAME, "ExecNode")

    def CollectToolMetaData(self):
        return self.connection.Read(self.DB_NAME, "Tool")    
    
    def CollectNodeStatusMetaData(self, node):
        metadata = self.connection.Read(self.DB_NAME, "NodeRuntime", {"node" : str(node)} ) 
        jsonData=list() 
        if metadata:
            jsonData = metadata[0]
        return jsonData     

    def ExecGraphDataExists(self):
        return self.connection.CountDocs(self.DB_NAME, "ExecNode") > 0

    def IsExecNodeDependency(self, node):
        # cases to catch in node dependencies:
        # '"n ' 
        # ' n '
        # ' n"'
        # '"n"'
        metadata = self.connection.Read(self.DB_NAME, "ExecNode", {"-d": { "$regex" : "\"" + str(node) +" | " + str(node) + " | " + str(node) + "\" | \"" + str(node) + "\"" }} ) 
        if metadata and len(metadata) > 0:
            return True
        return False

    def CollectExecNodesMetaData(self):
        metadata = self.connection.Read(self.DB_NAME, "ExecNode", {"job" : { "$exists" : "true" } } ) 
        return metadata             

    def CollectExecNodeMetaData(self, node):
        metadata = self.connection.Read(self.DB_NAME, "ExecNode", {"job" : str(node)} ) 
        jsonData=list() 
        if metadata:
            jsonData = metadata[0]
        return jsonData             
       
    def CollectNodeVarMetaDataById(self, id):
        metadata = self.connection.Read(self.DB_NAME, "NodeVar", {"_id" : id } ) 
        jsonData=list() 
        if metadata:
            jsonData = metadata[0]
        return jsonData     

    def CollectNodeVarMetaDataByNodeValueType(self, node, name, type):
        metadata = self.connection.Read(self.DB_NAME, "NodeVar", { "$and" : [{"type" : type}, {"node" : str(node)}, {"name" : name} ]} ) 
        jsonData=list() 
        if metadata:
            jsonData = metadata[0]
        return jsonData     
        
    
    def CollectMetaData(self, tname):
        # being called async for gvars - expected
        # being called twice for gexec - mmm ?
        self.lg.Print(f"Collecting Data from {tname}")

        self.IntegrityCheck(tname)

        if tname.lower() == "graph":
            MetaData = self.CollectGraphMetaData()
        elif tname.lower() == "gvars":
            MetaData = self.CollectGVarsMetaData()
        elif tname.lower() == "gexec":
            MetaData = self.CollectGExecMetaData()
        elif tname.lower() == "project":
            MetaData = self.CollectProjectMetaData()
        elif tname.lower() == "tool":
            MetaData = self.CollectToolMetaData()            
        return MetaData
    
    def CollectAllMetaDataForGivenNodesAndProject(self, nodes, clean):
        unique_nodes = list(set(nodes.split()))
        node_array = ' '.join(f'{w}' for w in unique_nodes).split()
        node_data = self.connection.Read(self.DB_NAME, "Node", {"node" : { "$in": node_array } } )
        if not clean:
            node_status_data = self.connection.Read(self.DB_NAME, "NodeRuntime", {"node" : { "$in": node_array } } )
            node_var_data = self.connection.Read(self.DB_NAME, "NodeVar", {"node" : { "$in": node_array } } )
            node_exec_data = self.connection.Read(self.DB_NAME, "ExecNode", {"job" : { "$in": node_array } } )
        param_data = self.connection.Read(self.DB_NAME, "Parameter", {} )
        project_data = self.connection.Read(self.DB_NAME, "Project", {} )
        scenario_data = self.connection.Read(self.DB_NAME, "Scenario", {} )
        tool_data = self.connection.Read(self.DB_NAME, "Tool", {} )
        migration_data = self.connection.Read(self.DB_NAME, "migration" )
        node_data_dict = {}
        node_data_dict["node_data"] = node_data
        if not clean:
            node_data_dict["status_data"] = node_status_data
            node_data_dict["var_data"] = node_var_data
            node_data_dict["exec_data"] = node_exec_data
        node_data_dict["param_data"] = param_data
        node_data_dict["project_data"] = project_data
        node_data_dict["scenario_data"] = scenario_data
        node_data_dict["tool_data"] = tool_data
        node_data_dict["migration_data"] = migration_data
        
        return node_data_dict
    
    def PersistAllMetaDataForNodes(self, node_data_dict, clean):
        for node in node_data_dict["node_data"]:
            self.connection.Create(self.DB_NAME, "Node", node)
        if not clean:
            for runtime_node in node_data_dict["status_data"]:
                runtime_node_dict = {}
                runtime_node_dict["_id"] = runtime_node["node"]
                runtime_node_dict.update(runtime_node)
                self.connection.Create(self.DB_NAME, "NodeRuntime", runtime_node_dict)
            for var in node_data_dict["var_data"]:
                self.connection.Create(self.DB_NAME, "NodeVar", var)
            for execNode in node_data_dict["exec_data"]:
                self.connection.Create(self.DB_NAME, "ExecNode", execNode)
        for param in node_data_dict["param_data"]:
            self.connection.Create(self.DB_NAME, "Parameter", param)
        self.connection.Create(self.DB_NAME, "Project", node_data_dict["project_data"][0])
        for scenario in node_data_dict["scenario_data"]:
            self.connection.Create(self.DB_NAME, "Scenario", scenario)
        for tool in node_data_dict["tool_data"]:
            self.connection.Create(self.DB_NAME, "Tool", tool)
        self.connection.Create(self.DB_NAME, "migration", node_data_dict["migration_data"][0])

    def GetVarValuesForNode(self, node):
        metadata = self.connection.Read(self.DB_NAME, "NodeVar", {"node" : str(node)} ) 
        nameValDict = {}
        if metadata:
            for var in metadata:
                nameValDict[var["name"]] = var["value"]    
        return nameValDict



    def GetExecNodeList(self):
        execNodeMetaDataList = self.CollectMetaData("gexec")
        execNodes = list()
        if execNodeMetaDataList:
            for execNodeEntry in execNodeMetaDataList:
                if "job" in execNodeEntry.keys():
                    execNodes.append( execNodeEntry["job"] )
        return execNodes
                
    def WriteGraphData(self, ddList):
        try:
            self._FlushMetaData('graph', 'tobackup')

            escapedList = (ddList.replace("\"", "\\\""))
            graph = json.loads(escapedList.replace("'",'"'))
            #print (f"MongoPersis.WriteGraphData() - {graph}")
            if bool(graph["tools"]):
                self.connection.Create(self.DB_NAME, "Tool", graph['tools'], True)
            if bool(graph["params"]):
                self.connection.Create(self.DB_NAME, "Parameter", graph['params'], True)
            if bool(graph["scenarios"]):
                self.connection.Create(self.DB_NAME, "Scenario", graph['scenarios'], True)
            if bool(graph["nodes"]):
                self.connection.Create(self.DB_NAME, "Node", graph['nodes'], True)
            if bool(graph["variables"]):
                self.connection.Create(self.DB_NAME, "Variable", graph['variables'], True)

            #no exception, so remove backup
            self._FlushMetaData('graph', 'removebackup')
            return True

        except Exception as ex:
            self.lg.Print ("Exception writing graph data: ", ex)
        return False
    
    def Collections(self, tname):
        collections = []
        if tname == 'gvars':
            collections.append('NodeVar')
        elif tname == 'gexec':
            collections.append('ExecNode')
        elif tname == 'graph':
            collections.append('Tool')
            collections.append('Parameter')
            collections.append('Variable')
            collections.append('Scenario')
            collections.append('Node')
        return collections

    def FlushMetaData(self, tname):
        return self._FlushMetaData(tname , "" )

    def _FlushMetaData(self, tname, action):
        try:
            self.lg.Print (f'_FlushMetaData {tname}, action = {action}')
            collections = self.Collections(tname)

            for collection in collections:
                if action == "tobackup":
                    self.connection.Rename(self.DB_NAME, collection, collection + '_bak')
                elif action == "removebackup":
                    self.connection.Remove(self.DB_NAME, collection + '_bak')
                else:
                    self.connection.Remove(self.DB_NAME, collection)
            return True
        
        except Exception as ex:
            self.lg.Print ("Exception _FlushMetaData: ", ex)
            return False

    def IntegrityCheck(self, tname):
        try:
            self.lg.Print(f'IntegrityCheck {tname}')
            for collection in self.Collections(tname):
                self.lg.Print (f".. {collection}")
                self.connection.Restore(self.DB_NAME, collection)

            return True
        
        except Exception as ex:
            self.lg.Print ("Exception IntegrityCheck: ", ex)
            return False
        



    def RemoveOrphanedVarNodeData(self, var_list):
        try:
            query = '{ "name": {"$nin":' + var_list + '} }'
            self.DeleteData('NodeVar', query)
            return True
        except Exception as ex:
            self.lg.Print(f"RemoveOrphanedVarNodeData exception:{ex}")
            return False

    
    def DeleteExtraDataFromExecNode(self):
        checkQuery = '{ "check": {"$regex": ".*"} }'
        fileQuery = '{ "file": {"$regex": ".*"} }'
        nameQuery = '{ "name": {"$regex": ".*"} }'
        self.DeleteData('ExecNode', checkQuery)
        self.DeleteData('ExecNode', fileQuery)
        self.DeleteData('ExecNode', nameQuery)

    def DeleteVarNodeTypeData(self, node, type):
        try:
            query_dict = { "node": node, "type": type }
            self.connection.Delete(self.DB_NAME,'NodeVar', query_dict, True )
        except Exception as e:
            self.lg.Print(f"DeleteVarNodeTypeData exception {e}")            
    
    def DeleteData(self, collection, mongoQueryStr = None):
        if (mongoQueryStr != None):
            mongoQuery = ast.literal_eval(mongoQueryStr)
        else:
            mongoQuery = None
        return self.connection.Delete(self.DB_NAME, collection, mongoQuery, True)
        