import json
import os
from platform import release
import socket
import threading
from queue import Queue, Empty
from threading import Lock
from threading import Event
from time import time, sleep
from tokenize import Ignore
from bson.json_util import dumps
from dataclasses import dataclass
from swbutils.model.Singleton import singleton
from swbutils.mongo.mongodb import MongoDB
from swbutils.mongo.mongologger import MongoLogger
from swbutils.mongo.mongomon import MongoMon
from swbutils.mongo.mongoswboperations import MongoSwbOperations

@singleton
class MongoStreams:
    
    def __init__(self):
        self.lg = MongoLogger()
        self.pid = os.getpid()
        self.node_change_counter = 0
        self.observers = []
        self.observer_type = ""
        self.node_listener_started = False
        self.host_counters = {}
        self.client_sockets = {}
        self.cache_data = {}
        self.project = ""

        self.commsLock = Lock()
        self.nodeLock = Lock()

        
    def __ChangeListener(self, changeStream, queue, lock):
        try:
            for change in changeStream:
                lock.acquire() 
                try:
                    #self.lg.Print(f"change event: {change}")
                    queue.put(dumps(change))
                except Exception as e:
                    self.lg.Print(f"error parsing change: {e}")
                lock.release()
        except Exception as e:
            self.lg.Print(f"Change Stream Stopped : {e}")
            # In further might need to do some further error handling here.
            # At the moment we do not expect errors in normal running.
            # We might want to restart the streams if we know that the connection is still available
            # Or send the error to an observer for handling elsewhere.

    def StartNodeChangeListener(self, project, oberserver_type, retries = 10 ):

        if self.project != project:
            self.node_listener_started = False
        if not self.node_listener_started:
            self.node_event = threading.Event()
            self.project = project
            try:
                client = MongoMon().Connection(project).client
            except:
                self.lg.Print(f'No existing connection for {project}')
                return
            db = client["SynopsysSWB"]
            collection = db["NodeRuntime"]
            # Only interested in new document inserts or updates where the status field changes
            gui_filter = [ { "$match":{
                            "$or":[
                                {
                                "$and":[
                                    { "updateDescription.updatedFields.status":{ "$exists":"true" } },
                                    { "operationType":"update" } ]
                                },  
                                { "operationType":"insert" } ]
                            }
                        } ]
            gsub_filter = [ { "$match":{
                            "$or":[
                                {
                                "$and":[
                                    { "updateDescription.updatedFields.status":{ "$exists":"true" } },
                                    { "updateDescription.updatedFields.status":{ "$in": ["done", "failed", "aborted"] } }, 
                                    { "operationType":"update" } ]
                                }, 
                                { "$and": [ 
                                    { "operationType":"insert" },
                                    { "fullDocument.status":{ "$in": ["done", "failed", "aborted"] } } ]
                                } ]
                            }
                        } ]
            if oberserver_type == "gsub":
                filter = gsub_filter
            else:
                filter = gui_filter
            self.node_change_stream = collection.watch(filter, full_document='updateLookup')
            self.node_listener_started = True
            self.node_change_data_queue = Queue()
            threading.Thread( target=self.__ChangeListener, args=(self.node_change_stream, self.node_change_data_queue, self.nodeLock) ).start()
            threading.Thread(target = self.processNodeEvent, args=(project, self.nodeLock) ).start()
            
            
    def RegisterObserver(self, host, port, observer_type):
        # there should only be one mongo stream running for each binary which needs it, e.g. GUI or GSUB
        if port and host: 
            self.observers.append((host,int(port)))
            self.observer_type = observer_type
            #print (f"Registering {host}:{port} {observer_type} list - {self.observers}")

            return f"{host}:{port} registered - observer list {self.observers}"
    
    def DeregisterAllObservers(self):
        try:
            self.node_change_stream.close() 
            self.node_event.set()           
        except:
            pass
        self.node_listener_started = False
        self.observers = []

    def DeregisterObserver(self, host, port):
        #print (f"Deregistering observer called {host}:{port}  - observer list {self.observers}")
        if port and host and  ( (host,int(port)) in self.observers ):
            self.lg.Print (f"Deregistering {host}:{port}")
            self.observers.remove((host,int(port)))
            if len(self.observers)== 0:
                self.lg.Print("Closing Change Streams")
                try:
                    self.node_change_stream.close()
                    self.node_event.set()
                except:
                    pass
                self.node_listener_started = False
# FIX ME - Sockets close                
#                for socket in self.client_sockets:
#                    socket.close()
            return f"{host}:{port} deregistered"


    def UpdateHostCounter(self, host):
        if host in self.host_counters:
            self.host_counters[host] += 1
        else:
            self.host_counters[host] = 1 

    def SendMsgToHost(self, type):
        self.commsLock.acquire() 
        try:
            host = self.cache_data[type].host
            self.UpdateHostCounter(host)
            counter_str = str(self.host_counters[host])
            msg = self.cache_data[type].form_comms_message(counter_str)

            self.__send_comms_to_observers(msg)
        except Exception as e:
            self.lg.Print(f"SendMsgToHost: {e}")
        self.commsLock.release()

    def __ParseNodeChange(self, change_json, project):
        #self.lg.Print(f"change: json node change:{change_json}")
        data = ParsedData()
        parsed_dict = json.loads(change_json)
        data.timestamp = str(int(time()))
        data.status = ""
        data.host = "localhost"
        data.exectime = "0"
        data.current_job_id = "--"

        for k, v in parsed_dict["fullDocument"].items():
            if k == "status":
                data.status = v
            elif k == "timestamp":
                data.timestamp = str(v)
            elif k == "host":
                data.host = v
            elif k == "exectime":
                data.exectime = str(v)
            elif k == "pid":
                data.current_job_id = v
            elif k == "node":
                data.current_node = str(v) 
        data.parsed_success = True              
        return data

    def packNodeDataAndSend(self, parsed_data, node_list, job_id_list, send, finalise):
        self.lg.Print(f"packNodeDataAndSend : Send =  {send}")

        type = "node"
        if not type in self.cache_data:
            self.cache_data[type] = parsed_data

        if self.cache_data[type].status != parsed_data.status:
            send = True


        if send and ( len(node_list) > 0 or len(job_id_list) > 0):
            self.cache_data[type].node_list[:] = node_list
            self.cache_data[type].job_id_list[:] = job_id_list

            self.lg.Print(f"Sending nodes {node_list} at status {parsed_data.status} to observer {self.observer_type}")
            self.SendMsgToHost(type)
            self.cache_data[type].node_list.clear()
            self.cache_data[type].job_id_list.clear()
            node_list.clear()
            job_id_list.clear()
        if not finalise:
            node_list.append(parsed_data.current_node)
            job_id_list.append(parsed_data.current_job_id)
            self.cache_data[type] = parsed_data

        return send

    def processNodeEvent(self, project, lock):
        job_id_list = []
        node_list = []
        packsize = 10
        pack = packsize
        finalise = False
        sent = False

        parsed_data = ParsedData()
        while not self.node_event.isSet():
            try:
                lock.acquire()
                mongoChange = self.node_change_data_queue.get(timeout=0.01)
                lock.release()
                finalise = True
                parsed_data = self.__ParseNodeChange(mongoChange, project)
                pack -= 1
                sent = self.packNodeDataAndSend(parsed_data, node_list, job_id_list, bool(pack==0), False)
                if sent :
                    pack = packsize

            except Empty:
                lock.release()
                if finalise :
                    finalise = False
                    #self.lg.Print("Node Queue Empty")
                    sent = self.packNodeDataAndSend(parsed_data, node_list, job_id_list, True, True)

            except Exception as e:
                lock.release()
                self.lg.Print(f"Exception in processNodeEvent: {e}")


    def __send_comms_to_observers(self, comms_string, retries = 0 ):
        for client_socket_info in self.observers:
            #print(f"send comms to {client_socket_info[1]} {comms_string}")
            try:
                if not (client_socket_info[0],client_socket_info[1]) in self.client_sockets:
                    client_socket = socket.socket()
                    client_socket.connect((client_socket_info[0],client_socket_info[1]))                     
                    data = client_socket.recv(1024).decode()
                    self.client_sockets[(client_socket_info[0],client_socket_info[1])] = client_socket
                    if not data.startswith('ACCEPT'):
                        if retries < 3:
                            retries += 1
                            self.__send_comms_to_observers(comms_string, retries)
                        else:  
                            self.lg.Print("cannot open connection after retries")
                else:
                    client_socket = self.client_sockets[(client_socket_info[0],client_socket_info[1])]


                if client_socket.send(comms_string.encode()) > 0:
                    data = self.client_sockets[(client_socket_info[0],client_socket_info[1])].recv(1024).decode()
                    if not data.startswith('OK'):
                        self.lg.Print(f"problem sending comms to {client_socket_info[1]}, recv'd: {data}")
                        if retries < 3:
                            retries += 1
                            self.__send_comms_to_observers(comms_string, retries)
                        else:
                            self.lg.Print("cannot send data after retries")
                else:
                    self.lg.Print("did not send data")
                    self.client_sockets[(client_socket_info[0],client_socket_info[1])].pop()
                    self.__send_comms_to_observers(comms_string, retries)

            except Exception as e:
                #print(f"exception send comms to {client_socket_info[1]} error: {e}")
                pass

@dataclass
class ParsedData:

    timestamp: float = 0.0
    parsed_timestamp: str = ""
    parsed_string: str = ""
    status: str = ""
    node_list = []
    current_node: str = ""
    job_id_list = []
    current_job_id: str = ""
    host: str = ""

    exectime = 0
    parsed_success = False
    sent = False

    def __encode_value(self, field):
        return_val = ""
        for i in field:
            return_val+=str(ord(i))
            return_val+=":"
        return return_val[:-1]

    def form_comms_message(self, counter):


        #print(f"form_comms_message {self.host} {self.node_list} {self.status} counter {counter}")

        tcl_node_list = ""
        for node in self.node_list:
            tcl_node_list += str(node) + " "

        tcl_job_list = ""
        for job in self.job_id_list:
            tcl_job_list += json.dumps(job) + " "

        encoded_node = self.__encode_value(tcl_node_list.strip())
        encoded_host = self.__encode_value(self.host)
        encoded_job_id = self.__encode_value(tcl_job_list.strip())
        if not self.exectime.isnumeric():
            self.exectime = "0"
        encoded_start_time = self.__encode_value(self.exectime)
        encoded_status = self.__encode_value(self.status)

        msg =  f"{{{self.timestamp}|mongo|{self.host}|--|{counter}|CHANGE_NODE_STATUS|ARG|{encoded_node}|HOST|{encoded_host}|JOB_ID|{encoded_job_id}|NODE|{encoded_node}|STATUS|{encoded_status}|}}\n"

        return msg