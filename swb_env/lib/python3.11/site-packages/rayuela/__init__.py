"""TCAD's unified scheduling library.

.. todo::

    *   Use
        https://docs.dask.org/en/latest/configuration.html#downstream-libraries
        to manage this package configuration instead of setting values
        on import.
    *   Move process management code to a separate module.
"""


from __future__ import annotations


from functools import partial as _partial
from logging import getLogger as _get_logger

from os import (
    environ as _environ,
    getpid as _getpid,
    killpg as _killpg,
    setpgid as _setpgid,
)

from pathlib import Path as _Path
from shlex import split as _split

from signal import (
    SIGKILL as _SIGKILL,
    SIGTERM as _SIGTERM,
)

from subprocess import (
    CalledProcessError as _CalledProcessError,
    CompletedProcess as _CompletedProcess,
    PIPE as _PIPE,
    Popen as _Popen,
    TimeoutExpired as _TimeoutExpired,
)

from time import sleep as _sleep

from typing import (
    Callable as _Callable,
    Type as _Type,
)

from weakref import finalize as _finalize


from dask import (  # type: ignore
    config as _dask_configuration,
    delayed,
)

from distributed import get_worker as _get_worker  # type: ignore


try:
    from rayuela.infrastructures.infrastructure import Infrastructure as _Infrastructure

    _CDPLInfrastructure: _Type["_Infrastructure"] | None
    from .infrastructures.cdpl import CDPLInfrastructure as _CDPLInfrastructure

except Exception:
    _CDPLInfrastructure = None

from .infrastructures.dummy import DummyInfrastructure as _DummyInfrastructure
from .infrastructures.local import LocalInfrastructure as _LocalInfrastructure
from .infrastructures.lsf import LSFInfrastructure as _LSFInfrastructure

from .infrastructures.sge import (
    SGEInfrastructure as _SGEInfrastructure,
    SnpsSGEInfrastructure as _SnpsSGEInfrastructure,
)

from .infrastructures.slurm import SLURMInfrastructure as _SLURMInfrastructure

from .task import (
    Status,
    Task,
)

from .utils import generate_infinite as _generate_infinite


__all__ = [
    "delayed",
    "get_infrastructure",
    "report",
    "reports_until_finished",
    "reports",
    "statuses_until_stop",
    "statuses_until",
    "statuses",
    "submit_command",
    "submit",
]


_LOGGER = _get_logger(__name__)


def _read_rayuela_env_var(name, default, parser=int):
    if name in _environ:
        _LOGGER.debug(f"Setting {name} = {_environ[name]}")
        return parser(_environ[name])

    else:
        return default


_dask_configuration.set(
    {
        "distributed.scheduler.unknown-task-duration": "1m",
        "distributed.comm.retry.count": _read_rayuela_env_var(
            "RAYUELA_CONNECTION_RETRIES", 3
        ),
        "distributed.comm.timeouts.connect": _read_rayuela_env_var(
            "RAYUELA_CONNECTION_TIMEOUT", 120
        ),
        "distributed.scheduler.allowed-failures": _read_rayuela_env_var(
            "RAYUELA_TASK_RETRIES", 3
        ),
    }
)


_infrastructure_classes = {
    "dummy": _DummyInfrastructure,
    "local": _LocalInfrastructure,
    "lsf": _LSFInfrastructure,
    "sge": _SGEInfrastructure,
    "slurm": _SLURMInfrastructure,
    "snps": _SnpsSGEInfrastructure,
    **({} if _CDPLInfrastructure is None else {"cdpl": _CDPLInfrastructure}),
}


def get_infrastructure(infra_name=None, infra_class=None, infra_args={}):
    """Instantiate and return an infrastructure instance.

    This function is used by :func:`~rayuela.submit` to get new
    infrastructure instances. So, passing the same parameters
    (``infra_name``, ``infra_class`` and ``infra_args``) to this
    function will get you what :func:`~rayuela.submit` would use to
    execute tasks.
    """
    if infra_class is not None:
        return infra_class.get_unique(**infra_args)

    elif infra_name is not None:
        return get_infrastructure(
            infra_class=_infrastructure_classes[infra_name], infra_args=infra_args
        )

    else:
        return get_infrastructure("local", infra_args=infra_args)


def submit(
    *args, infra_name=None, infra_class=None, pure=True, infra_args={}, **kwargs
) -> Task:
    """Submit a task."""
    infra = get_infrastructure(infra_name, infra_class, infra_args)
    return infra.submit(*args, pure=pure, **kwargs)


def _stop_process_group(leader):
    """Gracefully stop a process group.

    .. todo::

        * Return the results of the ``communicate`` call.
        * Maybe also communicate after sending _SIGKILL.
    """
    _killpg(leader.pid, _SIGTERM)

    try:
        leader.communicate(timeout=10)

    except _TimeoutExpired:
        _killpg(leader.pid, _SIGKILL)


def _safe_communicate(process, timeout=1):
    """Call communicate and return the stdout and stderr of process.

    :raise _TimeoutExpired:
        if the process does not end in ``timeout`` seconds.

    .. note::

        This function is mainly needed as a workaround for
        https://bugs.python.org/issue35182.
    """
    try:
        return process.communicate(timeout=timeout)

    except ValueError as ve:
        if "Invalid file object" in str(ve):
            _LOGGER.warning(
                "The subprocess seems to have closed its pipes unexpectedly. See "
                "https://bugs.python.org/issue35182."
            )

            return _fallback_communicate(process, timeout)

        else:
            raise


def _fallback_communicate(process, timeout):
    """Wait timeout seconds and check if process is still running.

    If the process finished after timeout, return (None, None),
    representing the standard output and error respectively. Raise
    TimeoutExpired otherwise.
    """
    _sleep(timeout)

    if process.poll() is None:
        raise _TimeoutExpired(process.args, timeout)

    else:
        return None, None


def _manage_process(process):
    """Manage the lifecycle of a process (Popen object).

    This function is in charge of cancelling the process if the task was
    cancelled.

    .. todo::

        We may want to refactor this function:

        *   Put the first try block into a separate function and
            research about KeyError and ValueError.
        *   Put the contents of the while loop into a function.
        *   Return something meaningful if worker and task cannot be
            found.
    """
    try:
        worker = _get_worker()
        this_task = worker.get_current_task()

    except (KeyError, ValueError):
        # Somehow this can happen. We may want to communicate with the
        # process here and return something meaningful.
        _stop_process_group(process)
        return

    while this_task in worker.tasks:
        try:
            stdout, stderr = _safe_communicate(process)

        except _TimeoutExpired:
            continue

        else:
            if process.returncode == 0:
                return _CompletedProcess(
                    process.args, process.returncode, stdout, stderr
                )

            else:
                raise _CalledProcessError(
                    process.returncode, process.args, stdout, stderr
                )

    else:  # task has been cancelled
        _stop_process_group(process)


def _process_manager_task(
    command,
    stdout=None,
    stderr=None,
    shell=True,
    preexec_fn=lambda: _setpgid(_getpid(), _getpid()),
    **kwargs,
):
    """Rayuela task that manages a subprocess enabling cancellation."""
    try:
        with _Popen(
            command,
            stdout=stdout or _PIPE,
            stderr=stderr or _PIPE,
            shell=shell,
            preexec_fn=preexec_fn,
            **kwargs,
        ) as process:
            finalizer = _finalize(process, _killpg, process.pid, _SIGKILL)
            result = _manage_process(process)
            finalizer.detach()
            return result

    except AttributeError:
        if stdout and not hasattr(stdout, "fileno"):
            with _Path(stdout).open("wb") as stdout_file:
                return _process_manager_task(
                    command,
                    stdout_file,
                    stderr,
                    shell,
                    preexec_fn,
                    **kwargs,
                )

        elif stderr and not hasattr(stderr, "fileno"):
            with _Path(stderr).open("wb") as stderr_file:
                return _process_manager_task(
                    command,
                    stdout,
                    stderr_file,
                    shell,
                    preexec_fn,
                    **kwargs,
                )

        else:
            raise  # pragma: no cover

    except FileNotFoundError:
        return _process_manager_task(
            _split(command),
            stdout,
            stderr,
            shell,
            preexec_fn,
            **kwargs,
        )


def submit_command(command, *args, pure=False, metadata=None, **kwargs):
    r"""Submit a command line to an infrastructure.

    Example::

        >>> task = submit_command("echo success!")
        >>> task.get_result().stdout
        b'success!\n'
    """
    return submit(
        _process_manager_task,
        command,
        *args,
        metadata={"command": command, **(metadata or {})},
        pure=pure,
        **kwargs,
    )


statuses = _partial(_generate_infinite, lambda task: task.status)
statuses.__doc__ = "Yield the status of a task infinite times."


def statuses_until(task: Task, check: _Callable[[Task, Status], bool]):
    """Yield the status of a task until ``check`` returns ``True``.

    :param task: Task from which to fetch status information.

    :param check:
        A function that indicates when to stop yielding statuses.
    """
    for status in statuses(task):
        yield status

        if check(task, status):
            break


statuses_until_stop = _partial(
    statuses_until, check=lambda t, s: s not in (Status.PENDING, Status.RUNNING)
)
statuses_until_stop.__doc__ = "Yield the status of a task until the task stops running."


def report(tasks, _statuses=Status):
    """Return dict with all statuses mapping to task sets."""
    tasks = {*tasks}
    task_statuses = {t: t.status for t in tasks}
    return {s: {t for t in tasks if task_statuses[t] == s} for s in _statuses}


def reports(tasks, _report=report):
    """Yield an infinite number of task status reports."""
    tasks = {*tasks}

    yield from _generate_infinite(_report, tasks)


def reports_until_finished(tasks, _report_iter=reports, Status=Status):
    """Yield reports until there are no running or pending tasks left.

    Example::

        >>> from unittest.mock import MagicMock, PropertyMock
        >>> tasks = [MagicMock() for _ in range(2)]
        >>> type(tasks[0]).status = PropertyMock(
        ...     side_effect=[Status.RUNNING, Status.FINISHED, Status.FINISHED])
        >>> type(tasks[1]).status = PropertyMock(
        ...     side_effect=[Status.RUNNING, Status.RUNNING, Status.FINISHED])
        >>> for report in reports_until_finished(tasks):
        ...     print(f"Running: {len(report[Status.RUNNING])}")
        ...     print(f"Finished: {len(report[Status.FINISHED])}")
        ...     print(f"----------------------------------------")
        Running: 2
        Finished: 0
        ----------------------------------------
        Running: 1
        Finished: 1
        ----------------------------------------
        Running: 0
        Finished: 2
        ----------------------------------------
    """
    for report in _report_iter(tasks):
        yield report

        if report[Status.PENDING] | report[Status.RUNNING] == set():
            break


# ****************************************
# AppDigest signature for component RAYUELA. Do not delete!
# ****************************************
# @(&)Synopsys_Unique_Signature Libname="__init__.py" Name="RAYUELA" Version="4.0.0" Type="REUSE" Injector="V-2023.09-DEV (8729328)"(&)@
