"""Provide an abstraction of a Task in a scheduling system."""


from contextlib import contextmanager as _contextmanager
from datetime import datetime as _DateTime
from enum import Enum as _Enum
from pathlib import Path as _Path

from pickle import (
    dumps as _serialize,
    loads as _deserialize,
)

from types import MappingProxyType as _FrozenDict

from typing import (
    Mapping as _Mapping,
    Optional as _Optional,
)


from .infrastructures.dummy import DummyInfrastructure as _DummyInfrastructure

from .infrastructures.infrastructure import (
    Infrastructure as _Infrastructure,
    PathOrStr as _PathOrStr,
)

from .utils import (
    deep_dict_get as _deep_dict_get,
    no_default as _no_default,
    set_value_on_dynamic_dict as _set_value_on_dynamic_dict,
    stack_overflow_guard as _stack_overflow_guard,
)


class Status(_Enum):
    """Status of a :class:`Task`."""

    CANCELLED = "cancelled"
    ERROR = "error"
    FINISHED = "finished"
    LOST = "lost"
    PENDING = "pending"
    RUNNING = "running"


class Task:
    """A task in a scheduling system."""

    def __init__(
        self,
        future,
        infrastructure: _Optional[_Infrastructure] = None,
        metadata=None,
        name="",
        status_file: _Optional[_PathOrStr] = None,
        submit_time: _Optional[_DateTime] = None,
        tags=None,
    ):
        """Initialize instance attributes.

        .. todo::
            *   Document metadata attributes.

        .. note::
            Think twice before reordering attribute definitions in this
            method. They gradually enable class features that are used
            by other definitions in non-trivial ways.
        """
        super().__setattr__(
            "_serializers",
            {
                "finish_time": (_serialize, _deserialize),
                "name": (None, None),
                "status_file": (None, None),
                "submit_time": (_serialize, _deserialize),
                "tags": (tuple, frozenset),
            },
        )

        self.future = future
        self._infrastructure = infrastructure or _DummyInfrastructure(future.client)

        self._local_metadata = None
        """Store all the metadata after the task is cancelled.

        Cancelling a task frees the metadata stored on the scheduler.
        This is a problem, since many methods on this class rely on
        metadata to work. For example, the __repr__() method needs to
        access the metadata to get the name of the task.

        By creating a copy just before cancelling the task we avoid this
        problem and enable the object to keep functioning despite the
        real metadata being lost.

        .. todo::
            *   Make this thread safe.
            *   Avoid setting the metadata if this task already exists.
                Creating multiple Tasks with the same future will
                override metadata. This is a bug! We could check for the
                existence of the task key in the metadata to determine
                if we should initialize it or not.
        """

        self._set_metadata(self.key, {} if metadata is None else metadata)

        self.finish_time = None

        future.add_done_callback(
            # We are piercing encapsulation here, but this way we
            # prevent references to self to be passed down to the
            # lambda. Also, the client is accessed securely from a
            # different thread.
            lambda future: future.client.set_metadata(
                [future.key, "finish_time"], _serialize(_DateTime.now())
            )
        )

        self.name = name
        self.status_file = status_file
        self.submit_time = submit_time
        self.tags = set() if tags is None else tags

    def _set_metadata(self, keys, value):
        if self._local_metadata is not None:
            _set_value_on_dynamic_dict(self._local_metadata, keys, value)

        else:
            self._infrastructure.set_metadata(keys, value)

    @_stack_overflow_guard
    def _get_metadata(self, keys, default=_no_default):
        if self._local_metadata is not None:
            return _deep_dict_get(self._local_metadata, keys, default)

        else:
            return self._infrastructure.get_metadata(keys, default)

    def __getattr__(self, name):
        """Try to get an attribute from metadata."""
        if name in self._serializers:
            _, deserialize = self._serializers[name]
            data = self._get_metadata([self.key, name])
            return data if deserialize is None else deserialize(data)

        else:
            raise AttributeError(f"{name} is not defined in {self}.")

    def __setattr__(self, name, value):
        """Set an attribute, considering metadata attributes."""
        if name in self._serializers:
            serialize, _ = self._serializers[name]
            data = value if serialize is None else serialize(value)
            self._set_metadata([self.key, name], data)

        else:
            super().__setattr__(name, value)

    def __dir__(self):
        """Return a list of attrs, both metadata attrs and normal attrs."""
        return [*self._serializers.keys(), *super().__dir__()]

    def __repr__(self):
        """Return a representation of the task."""
        return f"<Task: name={self.name!r}, key={self.key!r}, status={self.status!r}>"

    @property
    def key(self):
        """Return task key."""
        return self.future.key

    @property
    def _internal_state(self) -> _Optional[str]:
        try:
            key = self.key  # passing key instead of self

            return self._infrastructure.run_on_scheduler(
                lambda dask_scheduler: dask_scheduler.tasks[key].state
            )

        except Exception:
            return None

    def _older_than_submit_time(self, file):
        file = _Path(file)
        return self.submit_time < _DateTime.fromtimestamp(file.stat().st_mtime)

    def _status_according_to_file(self, status_file):
        """Return the status of this task depending on ``status_file``.

        .. note::
            This is just a provisory implementation. The final
            implementation should be the one commented below. Please
            switch to the definitive implementation after Yong-Seog
            decides what to do with the delay problem.
        """
        import glob
        import os
        from datetime import datetime

        abspath = os.path.abspath(status_file)
        allfiles = os.path.dirname(abspath) + "/*"
        if abspath in glob.glob(allfiles) and self.submit_time < datetime.fromtimestamp(
            os.path.getmtime(abspath)
        ):
            return Status.FINISHED

        else:
            return Status.ERROR

        # status_file = _Path(status_file).expanduser().absolute()

        # # exists = status_file in status_file.parent.glob("*")
        # # exists = str(status_file) in glob.glob(f"{status_file.parent}/*")
        # exists = status_file.exists()

        # return (
        #     Status.FINISHED
        #     if exists and self._older_than_submit_time(status_file)
        #     else Status.ERROR
        # )

    @property
    def status(self):
        """Return task status."""
        future_status = Status(self.future.status)

        if self._internal_state == "processing":
            return Status.RUNNING

        elif future_status is Status.FINISHED and self.status_file is not None:
            return self._status_according_to_file(self.status_file)

        else:
            return future_status

    @property
    def metadata(self):
        """Task metadata."""
        metadata = self._get_metadata(self.key)

        for key, (_, deserialize) in self._serializers.items():
            if deserialize is None:
                continue

            else:
                metadata[key] = deserialize(metadata[key])

        return _FrozenDict(metadata)

    @metadata.setter
    def metadata(self, value: _Mapping):
        """Task metadata."""
        data = dict(value)

        for key, (serialize, _) in self._serializers.items():
            if serialize is None:
                continue

            elif key not in data:
                raise KeyError(
                    f'Required metadata attribute "{key} is not present in the '
                    f"provided mapping. Required attributes are: "
                    + ", ".join(f'"{k}"' for k in self._serializers.keys())
                    + "."
                )

            else:
                data[key] = serialize(data[key])

        self._set_metadata(self.key, data)

    def get_result(self):
        """Return the result of this task.

        .. note:: This is a blocking function.
        """
        return self._infrastructure.get_result(self.future)

    def retry(self):
        """Retry this task.

        .. todo::
            *   We may want to reset times and duration after retrying.
        """
        return self._infrastructure.retry(self.future)

    @_contextmanager
    def _handle_empty_submit_time(self, submit_time):
        try:
            yield

        except Exception as e:
            if submit_time is None:
                raise RuntimeError(
                    "This task's submit time is None. This may happen because the task "
                    "was directly created from a pre-existing Future."
                ) from e

            else:
                raise

    @property
    def elapsed_time(self):
        """Elapsed time since task submission."""
        with self._handle_empty_submit_time(self.submit_time):
            return _DateTime.now() - self.submit_time

    @property
    def duration(self):
        """Duration from task submission to task end."""
        if self.finish_time is None:
            """SCW does not seem to like duck typing. This if should be
            removed!"""
            return None

        try:
            with self._handle_empty_submit_time(self.submit_time):
                return self.finish_time - self.submit_time

        except TypeError:
            if self.finish_time is None:
                return None

            else:
                raise

    @property
    def native_job_ids(self):
        """Return tuple of job ids involved in processing this task."""
        return self._infrastructure.get_job_ids(self.future)

    @property
    def host_names(self):
        """Return tuple of host names involved in processing this task."""
        return self._infrastructure.get_host_names(self.future)

    def cancel(self):
        """Cancel this task."""
        self._local_metadata = {self.key: self._infrastructure.get_metadata(self.key)}
        self._infrastructure.cancel(self.future)


# ****************************************
# AppDigest signature for component RAYUELA. Do not delete!
# ****************************************
# @(&)Synopsys_Unique_Signature Libname="task.py" Name="RAYUELA" Version="4.0.0" Type="REUSE" Injector="V-2023.09-DEV (8729328)"(&)@
